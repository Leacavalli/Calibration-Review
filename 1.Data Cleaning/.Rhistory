# 0.2 Disease type
table(Calibration_data_V3$Disease.type..choose.all.that.apply.)
# 0.3 Model type
table(Calibration_data_V3$Model.type)
# 0.4 Stochasticity in model
table(Calibration_data_V3$Stochasticity.in.model)
# A.1 Scientific problem being solved (what is the purpose of calibration?)
table(Calibration_data_V3$Scientific.problem.being.solved)
# B.1.1. Beliefs or evidence
table(Calibration_data_V3$External.beliefs.or.evidence)
# B.1.2. Choice of parameters to calibrate
table(Calibration_data_V3$Choice.of.parameters.to.calibrate)
# B.1.3. What justification was provided for choice of parameters to calibrate? Only for studies which calibrated a subset of parameters.
table(Calibration_data_V3$What.justification.was.provided.for.choice.of.parameters.to.calibrate.)
# B.1.4. How many parameters were calibrated?
table(Calibration_data_V3$How.many.parameters.were.calibrated.)
# B.2.2. Resolution of data used for defining calibration targets
table(Calibration_data_V3$Resolution.of.data..used.for.defining.calibration.targets)
#  B.2.3.  How many calibration targets were used for estimation?
table(Calibration_data_V3$How.many.calibration.targets.were.used.for.estimation.)
# C.1. Number of steps
table(Calibration_data_V3$Number.of.steps..single.or.sequential.)
# C.2. Name of calibration algorithm
table(Calibration_data_V3$Name.of.calibration.algorithm)
# C.3. Is calibration implementation (code) available in an open-access repository?
table(Calibration_data_V3$Is.calibration.implementation..code..available.in.an.open.access.repository.)
# C.4. Goodness-of-fit (GOF) measure employed within calibration algorithm
table(Calibration_data_V3$Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm)
# C.5. What programming language was used for calibration?
table(Calibration_data_V3$What.programming.language.was.used.for.calibration.)
# C.6. Do authors list any programming packages used for calibration?
table(Calibration_data_V3$Do.authors.list.any.programming.packages.used.for.calibration.)
# D.1. Nature of calibration results
table(Calibration_data_V3$Nature.of.calibration.results)
# D.2. How are calibration results reported?
table(Calibration_data_V3$How.are.calibration.results.reported.)
# D.3. How is uncertainty in calibration outputs reported?
table(Calibration_data_V3$How.is.uncertainty.in.calibration.outputs.reported.)
# D.4. What is the size of the calibration output?
table(Calibration_data_V3  |>
mutate(size.of.the.calibration.output.reported = ifelse(What.is.the.size.of.the.calibration.output. == "Not reported", "Not reported", "[Number provided]"))|>
pull(size.of.the.calibration.output.reported))
# If number provided, what is the range of the reported size?
Calibration_data_V3  |>
mutate(size.of.the.calibration.output.reported = ifelse(What.is.the.size.of.the.calibration.output. == "Not reported", "Not reported", "[Number provided]"))|>
filter(size.of.the.calibration.output.reported != "Not reported")|>
pull(What.is.the.size.of.the.calibration.output.)
clean_data <- Calibration_data_V3
# 1. Model.type
# Check inconsistencies
clean_data |> group_by(Model.type) |> summarise(N=n())
clean_data |> filter(Model.type=="Other") |> select(Model.type, Other_Model.type)
clean_data |> filter(Other_Model.type != "", Model.type!="Other") |>select(Model.type, Other_Model.type)
# Clean inconsistencies
clean_data_V1 <- clean_data |> mutate(Other_Model.type = ifelse(Other_Model.type == "105 LMICs (Country names not reported)", "", Other_Model.type))
# 2. What.justification.was.provided.for.choice.of.parameters.to.calibrate
# Check inconsistencies
clean_data |> group_by(What.justification.was.provided.for.choice.of.parameters.to.calibrate.) |> summarise(N=n())
clean_data |>
filter(What.justification.was.provided.for.choice.of.parameters.to.calibrate.=="Other") |>
select(What.justification.was.provided.for.choice.of.parameters.to.calibrate., Other_What.justification.was.provided.for.choice.of.parameters.to.calibrate.)
clean_data |>
filter(Other_What.justification.was.provided.for.choice.of.parameters.to.calibrate. != "",
What.justification.was.provided.for.choice.of.parameters.to.calibrate.!="Other") |>
select(What.justification.was.provided.for.choice.of.parameters.to.calibrate., Other_What.justification.was.provided.for.choice.of.parameters.to.calibrate.)
# no inconsistencies
# 3. Other_Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.
# Check inconsistencies
clean_data |> group_by(Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.) |> summarise(N=n())
clean_data |>
filter(grepl("Other",Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.),
Other_Type.of.data.used.for.defining.calibration.targets..select.all.that.apply. == "")|>
select(Covidence.ID)
clean_data |>
filter(Other_Type.of.data.used.for.defining.calibration.targets..select.all.that.apply. != "",
! grepl("Other",Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.)) |>
select(Covidence.ID)
# no inconsistencies
# 4. Name.of.calibration.algorithm
# Check inconsistencies
clean_data |>
filter(Name.of.calibration.algorithm=="Other ") |>
filter(Other_Name.of.calibration.algorithm=="") |>
pull(Covidence.ID)
clean_data |>
filter(Other_Name.of.calibration.algorithm != "",
Name.of.calibration.algorithm !="Other ") |>
select(Name.of.calibration.algorithm, Other_Name.of.calibration.algorithm)
# Clean inconsistencies
clean_data_V2 <- clean_data_V1 |>
mutate(Other_Name.of.calibration.algorithm = ifelse(Other_Name.of.calibration.algorithm == "A Bayesian framework", "", Other_Name.of.calibration.algorithm))|>
mutate(Other_Name.of.calibration.algorithm = ifelse(Other_Name.of.calibration.algorithm == " ", "", Other_Name.of.calibration.algorithm))|>
mutate(Other_Name.of.calibration.algorithm = ifelse(Other_Name.of.calibration.algorithm == "Not reported", "", Other_Name.of.calibration.algorithm))
# 5. Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm
# Check inconsistencies
clean_data |>
filter(Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm=="Other ") |>
filter(Other_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm=="") |>
select(Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm, Other_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm, Not_Clear_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm)
clean_data |>
filter(Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm=="Not clear") |>
filter(Not_Clear_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm=="") |>
select(Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm, Other_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm, Not_Clear_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm)
# no inconsistencies
# 6. Nature.of.calibration.results
# Check inconsistencies
clean_data |>
filter(Nature.of.calibration.results=="Other ") |>
select(Nature.of.calibration.results, Other_Nature.of.calibration.results)
clean_data |>
filter(Other_Nature.of.calibration.results != "",
Nature.of.calibration.results != "Other ") |>
select(Nature.of.calibration.results, Other_Nature.of.calibration.results)
# no inconsistencies
# 7. How.are.calibration.results.reported.
# Check inconsistencies
clean_data |> group_by(How.are.calibration.results.reported.) |> summarise(N=n())
clean_data |> filter(Other_How.are.calibration.results.reported. != "")
# no inconsistencies
# 8. How.is.uncertainty.in.calibration.outputs.reported.
# Check inconsistencies
clean_data |> group_by(How.is.uncertainty.in.calibration.outputs.reported.) |> summarise(N=n())
clean_data |> filter(Other_How.is.uncertainty.in.calibration.outputs.reported. != "")
# no inconsistencies
# Final formating
clean_data_final <- clean_data_V2  |>
mutate(across(contains("Other_"), ~ ifelse(. == "", NA, .)))|>
mutate(across(contains("Not_Clear_"), ~ ifelse(. == "", NA, .)))
setwd("~/GitHub/Calibration-Review/1.Data Cleaning")
write.csv(clean_data_final, "Clean_data.csv", row.names = F)
clean_date_Model.type <- clean_date |> select(Model.type, Other_Model.type) |> filter(if_any(contains("Other_"), ~ !is.na(.)))
setwd("~/GitHub/Calibration-Review/1.Data Cleaning")
clean_date <- read.csv( "Clean_data.csv")
clean_date_Model.type <- clean_date |> select(Model.type, Other_Model.type) |> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_What.justification.was.provided.for.choice.of.parameters.to.calibrate. <- clean_date |> select(What.justification.was.provided.for.choice.of.parameters.to.calibrate., Other_What.justification.was.provided.for.choice.of.parameters.to.calibrate.)|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_Type.of.data.used.for.defining.calibration.targets..select.all.that.apply. <- clean_date |> select(Type.of.data.used.for.defining.calibration.targets..select.all.that.apply., Other_Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.)|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_Name.of.calibration.algorithm <- clean_date |> select(Name.of.calibration.algorithm, Other_Name.of.calibration.algorithm)|> filter(if_any(contains("Other_"), ~ !is.na(.)))|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm <- clean_date %>%
select(Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm,
Other_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm,
Not_Clear_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm) %>%
filter(if_any(matches("Other_|Not_Clear_"), ~ !is.na(.) & . != ""))
clean_date_Nature.of.calibration.results <- clean_date |> select(Nature.of.calibration.results, Other_Nature.of.calibration.results)|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_How.are.calibration.results.reported. <- clean_date |> select(How.are.calibration.results.reported., Other_How.are.calibration.results.reported.)|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_How.is.uncertainty.in.calibration.outputs.reported. <- clean_date |> select(How.is.uncertainty.in.calibration.outputs.reported., Other_How.is.uncertainty.in.calibration.outputs.reported.)|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm
clean_date_Model.type
clean_date_What.justification.was.provided.for.choice.of.parameters.to.calibrate.
clean_date_Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.
clean_date_Name.of.calibration.algorithm
clean_date_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm
# Write a file
library(xlsx)
setwd("~/GitHub/Calibration-Review/1.Data Cleaning")
write.xlsx(as.data.frame(clean_date_Model.type), file="Other_columns_check.xlsx", sheetName = "Model.type", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_What.justification.was.provided.for.choice.of.parameters.to.calibrate.), file="Other_columns_check.xlsx", sheetName = "What.justification.was.provided.for.choice.of.parameters.to.calibrate.", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.), file="Other_columns_check.xlsx", sheetName = "Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_Name.of.calibration.algorithm), file="Other_columns_check.xlsx", sheetName = "Name.of.calibration.algorithm", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm), file="Other_columns_check.xlsx", sheetName = "Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_Nature.of.calibration.results), file="Other_columns_check.xlsx", sheetName = "Nature.of.calibration.results", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_How.are.calibration.results.reported.), file="Other_columns_check.xlsx", sheetName = "How.are.calibration.results.reported.", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_How.is.uncertainty.in.calibration.outputs.reported.), file="Other_columns_check.xlsx", sheetName = "How.is.uncertainty.in.calibration.outputs.reported.", append=TRUE , row.names = F, col.names = T)
clean_date_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm <- clean_date %>%
select(Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm,
Other_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm,
Not_Clear_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm) %>%
filter(if_any(matches("Other_|Not_Clear_"), ~ !is.na(.) & . != "")) %>%
mutate(Other_or_Notclear = coalesce(Other_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm, Not_Clear_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm)) %>%
select(-Other_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm, -Not_Clear_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm)
clean_date_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm
setwd("~/GitHub/Calibration-Review/1.Data Cleaning")
clean_date <- read.csv( "Clean_data.csv")
clean_date_Model.type <- clean_date |> select(Model.type, Other_Model.type) |> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_What.justification.was.provided.for.choice.of.parameters.to.calibrate. <- clean_date |> select(What.justification.was.provided.for.choice.of.parameters.to.calibrate., Other_What.justification.was.provided.for.choice.of.parameters.to.calibrate.)|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_Type.of.data.used.for.defining.calibration.targets..select.all.that.apply. <- clean_date |> select(Type.of.data.used.for.defining.calibration.targets..select.all.that.apply., Other_Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.)|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_Name.of.calibration.algorithm <- clean_date |> select(Name.of.calibration.algorithm, Other_Name.of.calibration.algorithm)|> filter(if_any(contains("Other_"), ~ !is.na(.)))|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm <- clean_date %>%
select(Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm,
Other_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm,
Not_Clear_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm) %>%
filter(if_any(matches("Other_|Not_Clear_"), ~ !is.na(.) & . != "")) %>%
mutate(Other_or_Notclear = coalesce(Other_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm, Not_Clear_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm)) %>%
select(-Other_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm, -Not_Clear_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm)
clean_date_Nature.of.calibration.results <- clean_date |> select(Nature.of.calibration.results, Other_Nature.of.calibration.results)|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_How.are.calibration.results.reported. <- clean_date |> select(How.are.calibration.results.reported., Other_How.are.calibration.results.reported.)|> filter(if_any(contains("Other_"), ~ !is.na(.)))
clean_date_How.is.uncertainty.in.calibration.outputs.reported. <- clean_date |> select(How.is.uncertainty.in.calibration.outputs.reported., Other_How.is.uncertainty.in.calibration.outputs.reported.)|> filter(if_any(contains("Other_"), ~ !is.na(.)))
# Write a file
library(xlsx)
setwd("~/GitHub/Calibration-Review/1.Data Cleaning")
write.xlsx(as.data.frame(clean_date_Model.type), file="Other_columns_check.xlsx", sheetName = "Model.type", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_What.justification.was.provided.for.choice.of.parameters.to.calibrate.), file="Other_columns_check.xlsx", sheetName = "What.justification.was.provided.for.choice.of.parameters.to.calibrate.", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.), file="Other_columns_check.xlsx", sheetName = "Type.of.data.used.for.defining.calibration.targets..select.all.that.apply.", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_Name.of.calibration.algorithm), file="Other_columns_check.xlsx", sheetName = "Name.of.calibration.algorithm", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm), file="Other_columns_check.xlsx", sheetName = "Goodness.of.fit..GOF..measure.employed.within.calibration.algorithm", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_Nature.of.calibration.results), file="Other_columns_check.xlsx", sheetName = "Nature.of.calibration.results", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_How.are.calibration.results.reported.), file="Other_columns_check.xlsx", sheetName = "How.are.calibration.results.reported.", append=TRUE , row.names = F, col.names = T)
write.xlsx(as.data.frame(clean_date_How.is.uncertainty.in.calibration.outputs.reported.), file="Other_columns_check.xlsx", sheetName = "How.is.uncertainty.in.calibration.outputs.reported.", append=TRUE , row.names = F, col.names = T)
# Across VoCs
Coding_iSNV_df <-  Analysis_VCF_metadata_iSNV |> filter(FUNCLASS_V2 !='NONE')
# Clean environment
rm( list = ls() )
# load necessary libraries
library(RColorBrewer)
library(tidyverse)
library(dplyr)
library(reshape2)
library(ggsci)
# load VCF and metadata data
setwd("~/GitHub/Sars-cov-2-Intrahost-Variation/2.Data_Cleaning")
Analysis_VCF <- read.csv("Analysis_VCF.csv") |> select(-X)
Analysis_metadata <- read.csv("Analysis_metadata.csv")|> select(-X)
Analysis_VCF_metadata <- left_join(Analysis_VCF, Analysis_metadata)
# Number of samples per VoC
N_VoC <- Analysis_metadata |>
group_by(VoC) |>
summarise(N_VoC=n())
# Subset iSNVs
Analysis_VCF_metadata_iSNV <- Analysis_VCF_metadata |>
filter(AF>0.05 & AF<0.95) |>
mutate(FUNCLASS_V2 = ifelse(IMPACT=="HIGH", "NONSENSE",
ifelse(IMPACT=="LOW", "SYNONYMOUS",
ifelse(IMPACT=="MODERATE", "MISSENSE",
ifelse(IMPACT=="MODIFIER", "NONE",IMPACT)))))
# Load dnds data
setwd("~/GitHub/Sars-cov-2-Intrahost-Variation/3. Data Analysis/3.3. Selection/DnDscv")
dnds_iSNV <- read.csv("dndsout_pergene.csv") |>
dplyr::rename("SYNONYMOUS"="n_syn", "MISSENSE"="n_mis", "NONSENSE"="n_non")|>
filter(VoC !="All")|>
mutate(ORF = ifelse(grepl("ORF1ab", gene_name),
ifelse(gene_name %in% c("ORF1ab:leader-protein", "ORF1ab:nsp2","ORF1ab:nsp3","ORF1ab:nsp4","ORF1ab:3C-like-proteinase","ORF1ab:nsp6","ORF1ab:nsp7", "ORF1ab:nsp8", "ORF1ab:nsp9", "ORF1ab:nsp10"), "ORF1a", "ORF1b"),
gene_name)) |>
mutate(gene_name = factor(gene_name , levels=c("ORF1ab:leader-protein", "ORF1ab:nsp2","ORF1ab:nsp3","ORF1ab:nsp4","ORF1ab:3C-like-proteinase","ORF1ab:nsp6","ORF1ab:nsp7", "ORF1ab:nsp8", "ORF1ab:nsp9", "ORF1ab:nsp10","ORF1ab:nsp11", "ORF1ab:RNA-dependent-RNA-polymerase","ORF1ab:helicase", "ORF1ab:3'-to-5'-exonuclease","ORF1ab:endoRNAse", "ORF1ab:2'-O-ribose-methyltransferase", "S", "ORF3a", "E", "M", "ORF6", "ORF7a", "ORF7b", "ORF8", "N", "ORF10"))) |>
mutate(VoC = factor(VoC, levels=c("Delta", "BA.1", "BA.2")))
dnds_iSNV_global <- read.csv("dndsout_global.csv")
# Make ORF length table
ORFs <- data.frame(ORF= c("5'UTR" ,"ORF1a", "ORF1b", "S", "ORF3a", "E", "M", "ORF6", "ORF7a", "ORF8", "N", "ORF10", "3'UTR"),
start= c(1, 266, 13483, 21563, 25393, 26245, 26523, 27202, 27394, 27894, 28274, 29558, 29675) ,
end= c(265, 13483, 21555, 25384, 26220, 26472, 27191, 27387, 27759, 28259, 29533, 29674,29903 )) |>
mutate(length_ORF=(end-start)+1)
ORFs[nrow(ORFs)+1,] <- c("UTR", NA, NA, 29903-sum(ORFs$length_ORF))
# make Gene length table
Genes <- data.frame(gene_name= c("ORF1ab:leader-protein", "ORF1ab:nsp2","ORF1ab:nsp3","ORF1ab:nsp4","ORF1ab:3C-like-proteinase","ORF1ab:nsp6","ORF1ab:nsp7", "ORF1ab:nsp8", "ORF1ab:nsp9", "ORF1ab:nsp10", "ORF1ab:RNA-dependent-RNA-polymerase","ORF1ab:helicase", "ORF1ab:3'-to-5'-exonuclease","ORF1ab:endoRNAse", "ORF1ab:2'-O-ribose-methyltransferase", "S", "ORF3a", "E", "M", "ORF6", "ORF7a", "ORF8", "N", "ORF10"),
start= c(266, 806, 2720, 8555, 10055, 10973, 11843, 12092, 12686, 13025, 13442, 16237, 18040, 19621, 20659, 21563, 25393, 26245, 26523, 27202, 27394, 27894, 28274, 29558) ,
end= c(805, 2719, 8554, 10054, 10972, 11842, 12091, 12685, 13024, 13441, 16236, 18039, 19620, 20658, 21552, 25384, 26220, 26472, 27191, 27387, 27759, 28259, 29533, 29674))|>
mutate(gene_name= factor(gene_name, levels=c("ORF1ab:leader-protein", "ORF1ab:nsp2","ORF1ab:nsp3","ORF1ab:nsp4","ORF1ab:3C-like-proteinase","ORF1ab:nsp6","ORF1ab:nsp7", "ORF1ab:nsp8", "ORF1ab:nsp9", "ORF1ab:nsp10", "ORF1ab:RNA-dependent-RNA-polymerase","ORF1ab:helicase", "ORF1ab:3'-to-5'-exonuclease","ORF1ab:endoRNAse", "ORF1ab:2'-O-ribose-methyltransferase", "S", "ORF3a", "E", "M", "ORF6", "ORF7a", "ORF8", "N", "ORF10")))
Genes$length_gene <- Genes$end +1 - Genes$start
# Assign each mutation to its corresponding gene
Mutations_with_genes <- Analysis_VCF_metadata_iSNV |>
filter(FUNCLASS_V2 !='NONE')|>
rowwise() |>
mutate(gene_name = Genes$gene_name[which(POS >= Genes$start & POS <= Genes$end)]) |>
ungroup()
# Across VoCs
rare_recurrent_iSNV_df <- Analysis_VCF_metadata_iSNV |>
filter(FUNCLASS_V2 !='NONE')|>
group_by(MUT, FUNCLASS_V2)|>
summarise(N=n(), .groups = 'drop')|>
mutate(type=  ifelse(N >=5, "recurrent", "rare"))
# Each VoCs
rare_recurrent_iSNV_perVoC_df <-  Analysis_VCF_metadata_iSNV |>
filter(FUNCLASS_V2 !='NONE')|>
group_by(MUT, FUNCLASS_V2, VoC)|>
summarise(N=n(), .groups = 'drop')|>
mutate(type=  ifelse(N >=5, "recurrent", "rare"))
library(ggh4x)
# Across VoCs
## Table
rare_recurrent_iSNV_df |>
group_by(type, FUNCLASS_V2)|>
summarise(Unique_N= n(), .groups = 'drop') |>
pivot_wider(names_from = FUNCLASS_V2, values_from = Unique_N)|>
mutate(MIS_SYN=round(MISSENSE/SYNONYMOUS, 2),
NON_SYN=round(NONSENSE/SYNONYMOUS, 2),
NONSYN_SYN=round((MISSENSE+NONSENSE)/SYNONYMOUS, 2))
## Plot
# rare_recurrent_iSNV_df |>
#   mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS")))|>
#   ggplot()+
#   geom_bar(aes(x=N, fill=FUNCLASS_V2))+
#   ggh4x::facet_grid2(. ~ type, scales = "free", independent = "y")+
#   force_panelsizes(cols = c(1, 5), respect = TRUE)+
#   scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
#   theme_classic()+
#   xlab("Number of samples")
# Each VoCs
## Table
rare_recurrent_iSNV_perVoC_df  |>
group_by(VoC, type, FUNCLASS_V2)|>
summarise(Unique_N= n(), .groups = 'drop')|>
pivot_wider(names_from = FUNCLASS_V2, values_from = Unique_N)|>
mutate(NONSENSE = ifelse(is.na(NONSENSE), 0, NONSENSE))|>
mutate(MIS_SYN=round(MISSENSE/SYNONYMOUS, 2),
NON_SYN=round(NONSENSE/SYNONYMOUS, 2),
NONSYN_SYN=round((MISSENSE+NONSENSE)/SYNONYMOUS, 2))
## Plot
rare_recurrent_iSNV_perVoC_df |>
mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS")),
VoC = factor(VoC, levels=c("Delta", "BA.1", "BA.2")))|>
ggplot()+
geom_bar(aes(x=N, fill=FUNCLASS_V2, alpha=type))+
ggh4x::facet_grid2(VoC ~ type, scales = "free", independent = "y")+
force_panelsizes(cols = c(1, 5), respect = TRUE)+
scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
scale_alpha_manual(name="Type", values=c(0.4, 1))+
theme_classic()+
xlab("Number of samples")
rare_recurrent_iSNV_df|>  filter(type== "recurrent", FUNCLASS_V2 == "NONSENSE")
nonsense_recurrent_MUT <- rare_recurrent_iSNV_df|>  filter(type== "recurrent", FUNCLASS_V2 == "NONSENSE") |> pull(MUT)
Mutations_with_genes  |> filter(MUT %in% nonsense_recurrent_MUT)|> select(MUT, POS, VoC, gene_name)
# Across VoCs
rare_recurrent_iSNV_df|>
group_by(type, FUNCLASS_V2)|>
summarise(Total= sum(N), .groups = 'drop') |>
pivot_wider(names_from = FUNCLASS_V2, values_from = Total)|>
mutate(MIS_SYN=round(MISSENSE/SYNONYMOUS, 2),
NON_SYN=round(NONSENSE/SYNONYMOUS, 2),
NONSYN_SYN=round((MISSENSE+NONSENSE)/SYNONYMOUS, 2))
# In each VoC
rare_recurrent_iSNV_perVoC_df|>
group_by(VoC, type, FUNCLASS_V2)|>
summarise(Total= sum(N), .groups = 'drop') |>
pivot_wider(names_from = FUNCLASS_V2, values_from = Total)|>
mutate(NONSENSE = ifelse(is.na(NONSENSE), 0, NONSENSE))|>
mutate(MIS_SYN=round(MISSENSE/SYNONYMOUS, 2),
NON_SYN=round(NONSENSE/SYNONYMOUS, 2),
NONSYN_SYN=round((MISSENSE+NONSENSE)/SYNONYMOUS, 2))
# Across VoCs
Coding_iSNV_df <-  Analysis_VCF_metadata_iSNV |> filter(FUNCLASS_V2 !='NONE')
Coding_iSNV_df_V2 <-  left_join(Coding_iSNV_df |> select(Sample, MUT, AF),
rare_recurrent_iSNV_df |> select(MUT, type, FUNCLASS_V2)) |>
mutate(AF_new = ifelse(AF>0.5, 1-AF, AF))
## Across Functional Class
Coding_iSNV_df_V2 |>
group_by(type) |>
summarise(median_AF= round(median(AF),3))
# Across Functional categories and VoCs, the median AF of recurring mutations (0.309) is higher than that of rare mutations (0.114). While most rare iSNVs are carried at frequencies below 0.25 within samples, recurrent iSNVs are found at either low (AF<0.25) or high frequencies (AF>0.75).
## Across Functional Class
Coding_iSNV_df_V2 |>
mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS"))) |>
ggplot()+
geom_violin(aes(x=FUNCLASS_V2, y=AF, fill=FUNCLASS_V2), alpha=0.7, color="white")+
geom_boxplot(aes(x=FUNCLASS_V2, y=AF), width=0.5, alpha=0) +
facet_grid(. ~ type)+
theme_classic()+
scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
theme_classic()+
xlab("")
Coding_iSNV_df_V2 |>
group_by(type,FUNCLASS_V2 ) |>
summarise(median_AF= round(median(AF),3))|>
pivot_wider(names_from = FUNCLASS_V2, values_from = median_AF)
# Further breaking it down, the median AF of rare mutations is low across functional types, with nonsense mutations having a particularly low median AF of 0.08, while  rare missense and synonymous have a median AF of 0.11 and 0.13, respectively. The median AF of recurrent mutations is higher than that of rare mutations among both misense and synonymous mutations, but not nonsense mutations. Specifically, among recurrent iSNVs, the AF of synonymous mutations is the highest, at 0.45 , followed by that of missense mutations at 0.30, while it is 0.06 for nonsense mutations. This confirms that nonsense mutations are under strong purifying selection, such they seldom recur, and are limited to particularly low AFs when they do. In turn, missense mutations appear enriched among recurrent as compared to rare iSNVs, and display higher AF, suggesting that positively selected for both across and within hosts (i.e. it confirms that they are not removed when they arise de novo). These patterns are consistent across VoCs (Figure XXX).
# Each VoCs
Coding_iSNV_df_VoC <-  left_join(Coding_iSNV_df |> select(Sample, MUT, AF, VoC),
rare_recurrent_iSNV_perVoC_df |> select(MUT, type, FUNCLASS_V2))
Coding_iSNV_df_VoC|>
mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS")),
VoC = factor(VoC, levels=c("Delta", "BA.1", "BA.2"))) |>
ggplot()+
geom_violin(aes(x=FUNCLASS_V2, y=AF_new, fill=FUNCLASS_V2, alpha=type), color="white")+
geom_boxplot(aes(x=FUNCLASS_V2, y=AF_new), width=0.5, alpha=0) +
facet_grid(VoC ~ type)+
theme_classic()+
scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
scale_alpha_manual(name="Type", values=c(0.4, 0.8))+
theme_classic()+
xlab("")
# Across VoCs
Coding_iSNV_df <-  Analysis_VCF_metadata_iSNV |> filter(FUNCLASS_V2 !='NONE') |>
mutate(AF_new = ifelse(AF>0.5, 1-AF, AF))
Coding_iSNV_df_V2 <-  left_join(Coding_iSNV_df |> select(Sample, MUT, AF),
rare_recurrent_iSNV_df |> select(MUT, type, FUNCLASS_V2))
## Across Functional Class
Coding_iSNV_df_V2 |>
group_by(type) |>
summarise(median_AF= round(median(AF),3))
# Across Functional categories and VoCs, the median AF of recurring mutations (0.309) is higher than that of rare mutations (0.114). While most rare iSNVs are carried at frequencies below 0.25 within samples, recurrent iSNVs are found at either low (AF<0.25) or high frequencies (AF>0.75).
## Across Functional Class
Coding_iSNV_df_V2 |>
mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS"))) |>
ggplot()+
geom_violin(aes(x=FUNCLASS_V2, y=AF, fill=FUNCLASS_V2), alpha=0.7, color="white")+
geom_boxplot(aes(x=FUNCLASS_V2, y=AF), width=0.5, alpha=0) +
facet_grid(. ~ type)+
theme_classic()+
scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
theme_classic()+
xlab("")
Coding_iSNV_df_V2 |>
group_by(type,FUNCLASS_V2 ) |>
summarise(median_AF= round(median(AF),3))|>
pivot_wider(names_from = FUNCLASS_V2, values_from = median_AF)
# Further breaking it down, the median AF of rare mutations is low across functional types, with nonsense mutations having a particularly low median AF of 0.08, while  rare missense and synonymous have a median AF of 0.11 and 0.13, respectively. The median AF of recurrent mutations is higher than that of rare mutations among both misense and synonymous mutations, but not nonsense mutations. Specifically, among recurrent iSNVs, the AF of synonymous mutations is the highest, at 0.45 , followed by that of missense mutations at 0.30, while it is 0.06 for nonsense mutations. This confirms that nonsense mutations are under strong purifying selection, such they seldom recur, and are limited to particularly low AFs when they do. In turn, missense mutations appear enriched among recurrent as compared to rare iSNVs, and display higher AF, suggesting that positively selected for both across and within hosts (i.e. it confirms that they are not removed when they arise de novo). These patterns are consistent across VoCs (Figure XXX).
# Each VoCs
Coding_iSNV_df_VoC <-  left_join(Coding_iSNV_df |> select(Sample, MUT, AF, VoC),
rare_recurrent_iSNV_perVoC_df |> select(MUT, type, FUNCLASS_V2))
Coding_iSNV_df_VoC|>
mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS")),
VoC = factor(VoC, levels=c("Delta", "BA.1", "BA.2"))) |>
ggplot()+
geom_violin(aes(x=FUNCLASS_V2, y=AF_new, fill=FUNCLASS_V2, alpha=type), color="white")+
geom_boxplot(aes(x=FUNCLASS_V2, y=AF_new), width=0.5, alpha=0) +
facet_grid(VoC ~ type)+
theme_classic()+
scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
scale_alpha_manual(name="Type", values=c(0.4, 0.8))+
theme_classic()+
xlab("")
# Each VoCs
Coding_iSNV_df_VoC <-  left_join(Coding_iSNV_df |> select(Sample, MUT, new_AF, VoC),
rare_recurrent_iSNV_perVoC_df |> select(MUT, type, FUNCLASS_V2))
# Each VoCs
Coding_iSNV_df_VoC <-  left_join(Coding_iSNV_df |> select(Sample, MUT, AF_new, VoC),
rare_recurrent_iSNV_perVoC_df |> select(MUT, type, FUNCLASS_V2))
Coding_iSNV_df_VoC|>
mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS")),
VoC = factor(VoC, levels=c("Delta", "BA.1", "BA.2"))) |>
ggplot()+
geom_violin(aes(x=FUNCLASS_V2, y=AF_new, fill=FUNCLASS_V2, alpha=type), color="white")+
geom_boxplot(aes(x=FUNCLASS_V2, y=AF_new), width=0.5, alpha=0) +
facet_grid(VoC ~ type)+
theme_classic()+
scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
scale_alpha_manual(name="Type", values=c(0.4, 0.8))+
theme_classic()+
xlab("")
# Across VoCs
Coding_iSNV_df <-  Analysis_VCF_metadata_iSNV |> filter(FUNCLASS_V2 !='NONE') |>
mutate(AF_new = ifelse(AF>0.5, 1-AF, AF))
Coding_iSNV_df_V2 <-  left_join(Coding_iSNV_df |> select(Sample, MUT, AF),
rare_recurrent_iSNV_df |> select(MUT, type, FUNCLASS_V2))
## Across Functional Class
Coding_iSNV_df_V2 |>
group_by(type) |>
summarise(median_AF= round(median(AF_new),3))
# Across VoCs
Coding_iSNV_df <-  Analysis_VCF_metadata_iSNV |> filter(FUNCLASS_V2 !='NONE') |>
mutate(AF_new = ifelse(AF>0.5, 1-AF, AF))
Coding_iSNV_df_V2 <-  left_join(Coding_iSNV_df |> select(Sample, MUT, AF_new),
rare_recurrent_iSNV_df |> select(MUT, type, FUNCLASS_V2))
## Across Functional Class
Coding_iSNV_df_V2 |>
group_by(type) |>
summarise(median_AF= round(median(AF_new),3))
# Across Functional categories and VoCs, the median AF of recurring mutations (0.309) is higher than that of rare mutations (0.114). While most rare iSNVs are carried at frequencies below 0.25 within samples, recurrent iSNVs are found at either low (AF<0.25) or high frequencies (AF>0.75).
## Across Functional Class
Coding_iSNV_df_V2 |>
mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS"))) |>
ggplot()+
geom_violin(aes(x=FUNCLASS_V2, y=AF_new, fill=FUNCLASS_V2), alpha=0.7, color="white")+
geom_boxplot(aes(x=FUNCLASS_V2, y=AF_new), width=0.5, alpha=0) +
facet_grid(. ~ type)+
theme_classic()+
scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
theme_classic()+
xlab("")
Coding_iSNV_df_V2 |>
group_by(type,FUNCLASS_V2 ) |>
summarise(median_AF= round(median(AF),3))|>
pivot_wider(names_from = FUNCLASS_V2, values_from = median_AF)
Coding_iSNV_df_V2 |>
group_by(type) |>
summarise(median_AF= round(median(AF_new),3))
Coding_iSNV_df_V2 |>
mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS"))) |>
ggplot()+
geom_violin(aes(x=FUNCLASS_V2, y=AF_new, fill=FUNCLASS_V2), alpha=0.7, color="white")+
geom_boxplot(aes(x=FUNCLASS_V2, y=AF_new), width=0.5, alpha=0) +
facet_grid(. ~ type)+
theme_classic()+
scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
theme_classic()+
xlab("")
Coding_iSNV_df_V2 |>
group_by(type,FUNCLASS_V2 ) |>
summarise(median_AF= round(median(AF_new),3))|>
pivot_wider(names_from = FUNCLASS_V2, values_from = median_AF)
# Each VoCs
Coding_iSNV_df_VoC <-  left_join(Coding_iSNV_df |> select(Sample, MUT, AF_new, VoC),
rare_recurrent_iSNV_perVoC_df |> select(MUT, type, FUNCLASS_V2))
Coding_iSNV_df_VoC|>
mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS")),
VoC = factor(VoC, levels=c("Delta", "BA.1", "BA.2"))) |>
ggplot()+
geom_violin(aes(x=FUNCLASS_V2, y=AF_new, fill=FUNCLASS_V2, alpha=type), color="white")+
geom_boxplot(aes(x=FUNCLASS_V2, y=AF_new), width=0.5, alpha=0) +
facet_grid(VoC ~ type)+
theme_classic()+
scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
scale_alpha_manual(name="Type", values=c(0.4, 0.8))+
theme_classic()+
xlab("")
0.097
Coding_iSNV_df_V2 |>
group_by(type) |>
summarise(median_AF= round(median(AF_new),2))
Coding_iSNV_df_V2 |>
group_by(type,FUNCLASS_V2 ) |>
summarise(median_AF= round(median(AF_new),3))|>
pivot_wider(names_from = FUNCLASS_V2, values_from = median_AF)
Coding_iSNV_df_VoC|>
mutate(FUNCLASS_V2= factor(FUNCLASS_V2, levels=c("NONSENSE", "MISSENSE", "SYNONYMOUS")),
VoC = factor(VoC, levels=c("Delta", "BA.1", "BA.2"))) |>
ggplot()+
geom_violin(aes(x=FUNCLASS_V2, y=AF_new, fill=FUNCLASS_V2, alpha=type), color="white")+
geom_boxplot(aes(x=FUNCLASS_V2, y=AF_new), width=0.5, alpha=0) +
facet_grid(VoC ~ type)+
theme_classic()+
scale_fill_manual(name="Functional\nCategory", values=brewer.pal(n = 4, name = "Set2"))+
scale_alpha_manual(name="Type", values=c(0.4, 0.8))+
theme_classic()+
xlab("")
